{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqLgeR9qLYYM",
        "outputId": "f21d069f-129f-4c63-c36a-1a3bed90be39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 970 images belonging to 2 classes.\n",
            "Found 206 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "31/31 [==============================] - 150s 5s/step - loss: 0.2056 - accuracy: 0.9258 - val_loss: 1.0453 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "31/31 [==============================] - 160s 5s/step - loss: 0.1607 - accuracy: 0.9443 - val_loss: 0.8582 - val_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "31/31 [==============================] - 173s 6s/step - loss: 0.1285 - accuracy: 0.9588 - val_loss: 1.3425 - val_accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "31/31 [==============================] - 164s 5s/step - loss: 0.1254 - accuracy: 0.9598 - val_loss: 1.0047 - val_accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "31/31 [==============================] - 158s 5s/step - loss: 0.1305 - accuracy: 0.9577 - val_loss: 0.9753 - val_accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "31/31 [==============================] - 163s 5s/step - loss: 0.1179 - accuracy: 0.9598 - val_loss: 0.9815 - val_accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "31/31 [==============================] - 170s 5s/step - loss: 0.1194 - accuracy: 0.9598 - val_loss: 0.9497 - val_accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "31/31 [==============================] - 177s 6s/step - loss: 0.1237 - accuracy: 0.9608 - val_loss: 0.8284 - val_accuracy: 0.5000\n",
            "Epoch 9/10\n",
            "31/31 [==============================] - 183s 6s/step - loss: 0.1522 - accuracy: 0.9392 - val_loss: 3.7543 - val_accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "31/31 [==============================] - 175s 6s/step - loss: 0.1343 - accuracy: 0.9546 - val_loss: 3.0014 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1729b4850>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "import os\n",
        "\n",
        "# Define input shape\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = Input(shape=input_shape)\n",
        "\n",
        "# Define the convolutional base using ResNet50\n",
        "conv_base = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)(input_layer)\n",
        "\n",
        "# Add BatchNormalization and MaxPooling layers\n",
        "x = BatchNormalization()(conv_base)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# Flatten the output of the convolutional base\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Reshape the output to have a time dimension\n",
        "x = tf.keras.layers.Reshape((1, -1))(x)\n",
        "\n",
        "# Define the LSTM layer\n",
        "x = LSTM(128)(x)\n",
        "\n",
        "# Add a Dense layer with 64 units and ReLU activation\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "# Add a Dropout layer with a rate of 0.5\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Add the output layer with a sigmoid activation\n",
        "output_layer = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define file paths to your training and validation data directories\n",
        "train_directory = '/Users/nithishkumar/Documents/deepfake-video-detection-project/final_dataset/train'\n",
        "val_directory = '/Users/nithishkumar/Documents/deepfake-video-detection-project/final_dataset/validation'\n",
        "\n",
        "# Define train_labels\n",
        "train_labels = [0] * len(os.listdir(os.path.join(train_directory, 'original')) + [1] * len(os.listdir(os.path.join(train_directory, 'deepfake'))))\n",
        "val_labels = [0] * len(os.listdir(os.path.join(val_directory, 'original')) + [1] * len(os.listdir(os.path.join(val_directory, 'deepfake'))))\n",
        "\n",
        "# Use data generators to load and preprocess the images\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define data generators for training and validation data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# Load and preprocess training and validation data using data generators\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_directory,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    val_directory,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
        "\n",
        "# Your model is now trained and ready for making predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zhs3SqYNLYYP",
        "outputId": "e72d686a-6315-4802-f239-dc21371ff3a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Save the model to a file\n",
        "model.save(\"deepfake_detection_model.h5\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.11.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}